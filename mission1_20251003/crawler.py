import requests
from bs4 import BeautifulSoup
import json
import datetime
import time

def fetch_reviews(hotel_url, pages=3, max_reviews=50):
    """ì•¼ë†€ì ìˆ™ì†Œ í›„ê¸° í˜ì´ì§€ì—ì„œ ìµœê·¼ 3~6ê°œì›” ë‚´ ë¦¬ë·° ìˆ˜ì§‘"""
    all_reviews = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/115.0 Safari/537.36"
    }

    for page in range(1, pages + 1):
        url = f"{hotel_url}?page={page}"
        print(f"[{page}í˜ì´ì§€ ìš”ì²­ ì¤‘] {url}")
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            print(f"âš ï¸ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            continue

        soup = BeautifulSoup(response.text, "html.parser")

        # HTML êµ¬ì¡° ì˜ˆì‹œ (ì‹¤ì œ classëª…ì€ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì •)
        review_blocks = soup.find_all("div", class_="review-block")

        for block in review_blocks:
            text_tag = block.find("div", class_="review-text")
            date_tag = block.find("span", class_="date")
            if not text_tag or not date_tag:
                continue

            review_text = text_tag.get_text(strip=True)
            review_date = date_tag.get_text(strip=True)
            all_reviews.append({"date": review_date, "text": review_text})

        time.sleep(1)  # ê³¼ë„í•œ ìš”ì²­ ë°©ì§€

    # ë‚ ì§œ í•„í„°ë§ (ìµœê·¼ 6ê°œì›” ì´ë‚´)
    cutoff_date = datetime.datetime.now() - datetime.timedelta(days=180)
    filtered = []
    for r in all_reviews:
        try:
            date_obj = datetime.datetime.strptime(r["date"], "%Y.%m.%d")
            if date_obj > cutoff_date:
                filtered.append(r)
        except:
            continue

    # ì¡°ê±´ í•„í„°ë§ (ë¦¬ë·° ìˆ˜ / ê¸€ì ìˆ˜)
    total_text = "".join([r["text"] for r in filtered])
    if len(filtered) < 3 or len(total_text) < 90:
        print("âš ï¸ í›„ê¸° ìˆ˜ ë¶€ì¡± í˜¹ì€ ê¸€ì ìˆ˜ ë¶€ì¡± â†’ ìš”ì•½ ë¶ˆê°€")
        return None

    # ìµœì‹ ìˆœ ì •ë ¬ í›„ 50ê°œê¹Œì§€ë§Œ ì‚¬ìš©
    filtered = sorted(filtered, key=lambda x: x["date"], reverse=True)[:max_reviews]
    print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(filtered)}ê°œ ë¦¬ë·°")

    return filtered


if __name__ == "__main__":
    # âš™ï¸ ì˜ˆì‹œ URL (ì‹¤ì œ ìˆ™ì†Œë³„ IDë¡œ ë³€ê²½)
    hotel_url = "https://www.yanolja.com/hotel/100123/reviews"

    reviews = fetch_reviews(hotel_url, pages=3)

    if reviews:
        with open("reviews.json", "w", encoding="utf-8") as f:
            json.dump(reviews, f, ensure_ascii=False, indent=2)
        print("ğŸ’¾ reviews.json íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    else:
        print("âŒ ì¡°ê±´ì— ë§ëŠ” ë¦¬ë·°ê°€ ì—†ì–´ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

